{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af901473-957d-4dc0-a9a0-c477e1f39043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports openCV library\n",
    "import cv2 \n",
    "# imports numpy library\n",
    "import numpy as np\n",
    "# imports the operating system library\n",
    "import os\n",
    "# imports the time library\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ef569-7542-4418-bfec-4dd5aa217f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the minimum confidence (to filter weak detections), \n",
    "# Non-Maximum Suppression (NMS) threshold, the green color, and the class name\n",
    "\n",
    "confidence_thresh = 0.5 # 50% for confidence threshold\n",
    "NMS_thresh = 0.0\n",
    "green = (0, 255, 0) # green color from BGR color format\n",
    "class_names = \"rad_less.names\" # path to .names file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedefab2-6a63-4d6e-b3ec-6c2aaec22ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the video capture object\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44078e3-7aa0-4638-a4c6-251413f2c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the class labels the model was trained on\n",
    "class_path = class_names  # unpack content of class\n",
    "with open(class_path, \"r\") as f:\n",
    "    classes = f.read().strip().split(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8a152-1d95-4014-9df6-1ab6afdec600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now load the configuration and weight files from disk\n",
    "\n",
    "yolo_config = \"rad_less.cfg\" # path to .cfg file alternatively .yaml file\n",
    "yolo_weights = \"rad_less.weights\" # path to .weights file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d373fd-89ed-46fc-862f-aa04dda30cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained yolo network\n",
    "net = cv2.dnn.readNetFromDarknet(yolo_config, yolo_weights)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fd402-f519-4694-8a80-2755dee9dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of all the layers in the network\n",
    "layer_names = net.getLayerNames()\n",
    "# Get the names of the output layers\n",
    "# output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "output_layers = net.getUnconnectedOutLayersNames()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41b652-fd21-4324-974e-ac76d06245e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop though each frame in the video stream\n",
    "while True:\n",
    "    # the start time to compute frame per sec (fps)\n",
    "    start = time.time()\n",
    "    \n",
    "    # read the video frame\n",
    "    success, frame = video_capture.read(0)\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "\n",
    "    # in absence of any more frames to show, break out of the while loop\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Now get the frame dimensions\n",
    "    # N.B: frames are just like cut out images from the video stream since a video is a collection of moving images\n",
    "    h = frame.shape[0]\n",
    "    w = frame.shape[1]\n",
    "\n",
    "    # create a blob from the image\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        frame, 1 / 255, (416, 416), swapRB=True, crop=False)\n",
    "    \n",
    "    # pass the blob through the network and get the output predictions\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(output_layers)\n",
    "\n",
    "    # create empty lists for storing the bounding boxes and confidences\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # loop over the output predictions\n",
    "    for output in outputs:\n",
    "        # loop over the detections\n",
    "        for detection in output:\n",
    "            # get the class ID and confidence of the detected object\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # filter out weak detections by keeping only those with a confidence\n",
    "            # above the minimum confidence threshold (i.e 0.5 in this case)\n",
    "            if confidence > confidence_thresh:\n",
    "                # perform element-wise multiplication to get the coordinates of the bounding box\n",
    "                box = [int(a * b) for a, b in zip(detection[0:4], [w, h, w, h])]\n",
    "                center_x, center_y, width, height = box\n",
    "                \n",
    "                # get the top-left corner of the bounding box\n",
    "                x = int(center_x - (width / 2))\n",
    "                y = int(center_y - (height / 2))\n",
    "\n",
    "                # append the bounding box and the confidence to their respective lists\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, width, height])\n",
    "    \n",
    "                # put bounding box coordinates in a list\n",
    "\n",
    "                output_data = [class_id, x, y, width, height]\n",
    "                output_data = [str(value) for value in output_data] \n",
    "                print(output_data, end=' ') # print output data in a straight line\n",
    "\n",
    "                file_name  = \"current/data2.txt\" #path to text file\n",
    "                \n",
    "                # code to write bounding box coordinates to the text file\n",
    "                with open(file_name, \"a\") as file:\n",
    "                    boundary_ordinates = ' '.join(output_data)\n",
    "                    file.write(boundary_ordinates + \"\\n\")\n",
    "\n",
    "        # apply non-maximum suppression to remove weak bounding boxes that overlap with others.\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_thresh, NMS_thresh)\n",
    "        # indices = indices.flatten()\n",
    "\n",
    "        for i in indices:\n",
    "            (x,y,w,h) = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), green, 2)\n",
    "            text = f\"{classes[class_ids[i]]}: {confidences[i] * 100:.2f}%\"\n",
    "            cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, green, 2)\n",
    "            \n",
    "            if len(output_data) > 1:\n",
    "                # print(len(output_data))\n",
    "                # save frame with bounding box\n",
    "                frame_copy = frame.copy()\n",
    "                cv2.imwrite(f\"frames2/frame_{time.time()}.jpg\", frame_copy)\n",
    "\n",
    "        #  end time to compute the frame per seconds (i.e fps)\n",
    "        end = time.time()\n",
    "\n",
    "        # next is to calculate the fps and draw it on the frame\n",
    "        fps = f\"FPS: {1/(end - start):.2f}\"\n",
    "        cv2.putText(frame, fps, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 8)\n",
    "\n",
    "\n",
    "            # now, code to display the frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "    # if the \"q\" key is pressed, the loop should instantly stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52e546-fefa-45c5-a985-647d6c4ee510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, release the video capture object\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e27905d-a23b-4fe4-9b96-fff9ef887f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully converted to classes.names\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb845d8-985e-4835-89a8-2d96658ca012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
